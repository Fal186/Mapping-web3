{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qgeFEmGO16r"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8KnOWZw6NI2"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRvKgWFiNX3e"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwrgGxyf6Vdx"
      },
      "source": [
        "# Setting seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_lFnQAn_19W"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04oLnrbGAyWv"
      },
      "outputs": [],
      "source": [
        "set_seed(43)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLw0U_AC6Yk7"
      },
      "source": [
        "# Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc5GbDOSnfWQ"
      },
      "outputs": [],
      "source": [
        "from requests import get as rget\n",
        "\n",
        "# Update URL to raw CSV file\n",
        "url = \"https://raw.githubusercontent.com/Fal186/Mapping-web3/refs/heads/main/dataset/web3_Stage1_industry_domain.csv\"\n",
        "\n",
        "res = rget(url)\n",
        "with open('file.csv', 'wb+') as f:\n",
        "    f.write(res.content)\n",
        "\n",
        "data_df = pd.read_csv('file.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jJ2uW5CNjz8"
      },
      "outputs": [],
      "source": [
        "data_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxzUuRJHOKuE"
      },
      "outputs": [],
      "source": [
        "data_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO28y2VC6gof"
      },
      "source": [
        "# Selecting required columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JgnlISoOf_h"
      },
      "outputs": [],
      "source": [
        "train_df = data_df[['text', 'Core Infrastructure & Protocols',\n",
        "       'Decentralized Finance (DeFi) & Financial Applications',\n",
        "       'Digital Assets & Collectibles (NFTs)',\n",
        "       'Decentralized Applications (DApps) & Gaming',\n",
        "       'DAO & Governance Mechanisms']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hz6ZEJtOnlf"
      },
      "outputs": [],
      "source": [
        "target_list = ['Core Infrastructure & Protocols',\n",
        "       'Decentralized Finance (DeFi) & Financial Applications',\n",
        "       'Digital Assets & Collectibles (NFTs)',\n",
        "       'Decentralized Applications (DApps) & Gaming',\n",
        "       'DAO & Governance Mechanisms']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hW73qJhhUQw"
      },
      "source": [
        "# Preparing the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g3eG-kvOwf6"
      },
      "outputs": [],
      "source": [
        "#Set Max Lenght, maksimal 512 (BERT)\n",
        "MAX_LEN = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQdNH7haO30v"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8E6m1usO7Xa"
      },
      "outputs": [],
      "source": [
        "#download the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrT5SmDGO_gj"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.title = df['text']\n",
        "        self.targets = self.df[target_list].values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index])\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1lpLevsPJJt"
      },
      "source": [
        "# Splitting & Tokenizing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_nXQi4tPCUK"
      },
      "outputs": [],
      "source": [
        "# Adjusting the train/validation/test split\n",
        "train_df, temp_df = train_test_split(data_df, test_size=0.2, random_state=43)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=43)\n",
        "\n",
        "# Reset the indices\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk-MQcxvAnHQ"
      },
      "source": [
        "##Checking your device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNg5war4AlXW"
      },
      "outputs": [],
      "source": [
        "# Checking for available device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yblYAb1MAmgU"
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ-ADhk5-faf"
      },
      "source": [
        "## Adding Class Weights to adjust class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsCxsYW--cHD"
      },
      "outputs": [],
      "source": [
        "# Calculate class weights based on the label distribution in the training data\n",
        "label_counts = train_df[target_list].sum(axis=0)\n",
        "total_counts = label_counts.sum()\n",
        "class_weights = total_counts / (len(target_list) * label_counts)\n",
        "class_weights_tensor = torch.tensor(class_weights.values).float().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afM-KLsyCQXP"
      },
      "outputs": [],
      "source": [
        "# Print class weights\n",
        "print(\"Class Weights Distribution:\")\n",
        "for label, weight in zip(target_list, class_weights):\n",
        "    print(f\"{label}: {weight:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T3mAiVQ-e90"
      },
      "outputs": [],
      "source": [
        "# Define the loss function with class weights\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l_uye-k-jQ6"
      },
      "source": [
        "##Label Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4hGv088nyoP"
      },
      "outputs": [],
      "source": [
        "# Label distribution in the training set\n",
        "train_counts = train_df[target_list].sum(axis=0)\n",
        "print(\"Label distribution in the training set:\\n\", train_counts)\n",
        "\n",
        "# Label distribution in the validation set\n",
        "val_counts = val_df[target_list].sum(axis=0)\n",
        "print(\"\\nLabel distribution in the validation set:\\n\", val_counts)\n",
        "\n",
        "# Label distribution in the test set\n",
        "test_counts = test_df[target_list].sum(axis=0)\n",
        "print(\"\\nLabel distribution in the test set:\\n\", test_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9aQvZ0HKU_Q"
      },
      "outputs": [],
      "source": [
        "train_texts = set(train_df['text'])\n",
        "val_texts = set(val_df['text'])\n",
        "test_texts = set(test_df['text'])\n",
        "\n",
        "overlap = train_texts.intersection(val_texts).union(train_texts.intersection(test_texts)).union(val_texts.intersection(test_texts))\n",
        "print(f\"Number of overlapping samples across splits: {len(overlap)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKZbC_uaoSyg"
      },
      "outputs": [],
      "source": [
        "# Label distribution in the training set\n",
        "train_counts_percentage = (train_df[target_list].sum(axis=0) / len(train_df)) * 100\n",
        "print(\"Label distribution in the training set:\\n\", train_counts_percentage)\n",
        "\n",
        "# Label distribution in the validation set\n",
        "val_counts_percentage = (val_df[target_list].sum(axis=0) / len(val_df)) * 100\n",
        "print(\"\\nLabel distribution in the validation set:\\n\", val_counts_percentage)\n",
        "\n",
        "# Label distribution in the test set\n",
        "test_counts_percentage = (test_df[target_list].sum(axis=0) / len(test_df)) * 100\n",
        "print(\"\\nLabel distribution in the test set:\\n\", test_counts_percentage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eIYUWIEPP_a"
      },
      "outputs": [],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL-QBdXjYfOK"
      },
      "outputs": [],
      "source": [
        "val_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WXN8fBZPSUp"
      },
      "outputs": [],
      "source": [
        "val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT2YFEs5n7oK"
      },
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMfVZre2PVRS"
      },
      "outputs": [],
      "source": [
        "# Create the CustomDataset for each set\n",
        "train_dataset = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
        "valid_dataset = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
        "test_dataset = CustomDataset(test_df, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhaZ2dN6PePv"
      },
      "outputs": [],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHUEw5zmhq3A"
      },
      "source": [
        "# Setting hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X99uZ4eYhGp3"
      },
      "outputs": [],
      "source": [
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 3e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPQiQ8v2Pgmr"
      },
      "outputs": [],
      "source": [
        "# Preparing the DataLoaders\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzjEWgTiAmn"
      },
      "source": [
        "# Additional functions for loading and saving checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK-rRna-P9cd"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into\n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoc8eLxMQEYL"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBOfVICFjhOo"
      },
      "source": [
        "Defining and Initializing the BERT Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVX-Zl9wP_K-"
      },
      "outputs": [],
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('google-bert/bert-base-uncased', return_dict=True)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.linear = torch.nn.Linear(768, 5)\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
        "        output = self.bert_model(\n",
        "            input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "        output_dropout = self.dropout(output.pooler_output)\n",
        "        output = self.linear(output_dropout)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Faa0Pam47V9T"
      },
      "source": [
        "Setting Up the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD5bZyhYQFpA"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "optimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yBE580aQLym"
      },
      "source": [
        "Initialization of Validation Target and Output Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4PjkTM3QK-6"
      },
      "outputs": [],
      "source": [
        "val_targets=[]\n",
        "val_outputs=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSqb4o657dN2"
      },
      "source": [
        "Training and Validation Loop with Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_48OeKUvQVq2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    # Save checkpoint\n",
        "    torch.save(state, checkpoint_path)\n",
        "    # If it is the best model, save it separately\n",
        "    if is_best:\n",
        "        torch.save(state['state_dict'], best_model_path)\n",
        "        print(f\"Best model saved to {best_model_path}\")\n",
        "\n",
        "def train_model(n_epochs, training_loader, validation_loader, model,\n",
        "                optimizer, checkpoint_path, best_model_path, patience):\n",
        "\n",
        "    # Initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.inf\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "\n",
        "        model.train()\n",
        "        print(f'############# Epoch {epoch}: Training Start   #############')\n",
        "        for batch_idx, data in enumerate(training_loader):\n",
        "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
        "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
        "\n",
        "        print(f'############# Epoch {epoch}: Training End     #############')\n",
        "\n",
        "        print(f'############# Epoch {epoch}: Validation Start   #############')\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, data in enumerate(validation_loader, 0):\n",
        "                ids = data['input_ids'].to(device, dtype=torch.long)\n",
        "                mask = data['attention_mask'].to(device, dtype=torch.long)\n",
        "                token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "                targets = data['targets'].to(device, dtype=torch.float)\n",
        "                outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "                loss = loss_fn(outputs, targets)\n",
        "                valid_loss += ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
        "\n",
        "        train_loss /= len(training_loader)\n",
        "        valid_loss /= len(validation_loader)\n",
        "        print(f'Epoch: {epoch} \\tAverage Training Loss: {train_loss:.6f} \\tAverage Validation Loss: {valid_loss:.6f}')\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': valid_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "        # Save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model ...')\n",
        "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "            valid_loss_min = valid_loss\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            print(f\"No improvement in validation loss for {no_improve} epoch(s).\")\n",
        "\n",
        "        # Early stopping\n",
        "        if no_improve >= patience:\n",
        "            print(\"Early stopping due to no improvement in validation loss.\")\n",
        "            break\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnK17lGT-Oel"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(\"/content/gdrive/MyDrive/ckpt_path\", exist_ok=True)\n",
        "os.makedirs(\"/content/gdrive/MyDrive/Best_Model\", exist_ok=True)\n",
        "\n",
        "# Define paths for checkpoint and best model\n",
        "ckpt_path = \"/content/gdrive/MyDrive/Best_Model/best_model(32-3e-5-stage1-BERT-class-weightsv2).pth\"\n",
        "best_model_path = \"/content/gdrive/MyDrive/ckpt_path/ckpth(32-3e-5-stage1-BERT-class-weightsv2).pth\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXx9N3L2ic4E"
      },
      "source": [
        "# Start Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpt2jMurQdgX"
      },
      "outputs": [],
      "source": [
        "trained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, ckpt_path, best_model_path, patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-Rz2GtX4lPK"
      },
      "outputs": [],
      "source": [
        "# Change in ipython-input-34-9f9b812337c3\n",
        "# Load the saved model's state_dict directly instead of using load_ckp\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "# Print a message indicating successful loading\n",
        "print(f'Loaded model state_dict from {best_model_path}')\n",
        "\n",
        "# Now, if you need the validation loss (valid_loss_min) or start epoch:\n",
        "# you should load from the checkpoint file (ckpt_path) instead\n",
        "checkpoint = torch.load(ckpt_path)\n",
        "start_epoch = checkpoint['epoch']\n",
        "valid_loss_min = checkpoint['valid_loss_min']\n",
        "\n",
        "print(f'The validation loss of the best saved model is: {valid_loss_min}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_DZdWyDcLeO"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQmoNLIfcMud"
      },
      "outputs": [],
      "source": [
        "# Process new dataset\n",
        "#new_df =pd.read_excel(\"/content/combined_dataset_TEST_NEW.xlsx\")\n",
        "#new_dataset = CustomDataset(new_df, tokenizer, MAX_LEN)\n",
        "new_dataset = test_dataset\n",
        "\n",
        "# Create DataLoader\n",
        "new_data_loader = torch.utils.data.DataLoader(new_dataset,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# Load the model\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "checkpoint = torch.load(ckpt_path)\n",
        "start_epoch = checkpoint['epoch']\n",
        "valid_loss_min = checkpoint['valid_loss_min']\n",
        "\n",
        "# Switch model to the evaluation mode\n",
        "model.eval()\n",
        "\n",
        "new_outputs = []\n",
        "new_targets = []\n",
        "test_loss = 0.0\n",
        "\n",
        "# Define loss function\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Pass new data through the model\n",
        "with torch.no_grad():\n",
        "    for batch_idx, data in enumerate(new_data_loader):\n",
        "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        test_loss += loss.item() * data['input_ids'].size(0)\n",
        "\n",
        "        new_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "        new_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "\n",
        "# Average the test loss over all batches\n",
        "test_loss = test_loss / len(new_data_loader.dataset)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.6f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjjEDclse1Wm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert the outputs and targets to numpy arrays\n",
        "new_outputs_np = np.array(new_outputs)\n",
        "new_targets_np = np.array(new_targets)\n",
        "\n",
        "# Threshold the outputs (This depends on your requirements, 0.5 is used as an example)\n",
        "new_outputs_bin = (new_outputs_np > 0.5)\n",
        "\n",
        "# Calculate metrics\n",
        "print(classification_report(new_targets_np, new_outputs_bin))\n",
        "\n",
        "# Calculate macro and micro metrics\n",
        "precision_macro = precision_score(new_targets_np, new_outputs_bin, average='macro')\n",
        "recall_macro = recall_score(new_targets_np, new_outputs_bin, average='macro')\n",
        "f1_macro = f1_score(new_targets_np, new_outputs_bin, average='macro')\n",
        "\n",
        "precision_micro = precision_score(new_targets_np, new_outputs_bin, average='micro')\n",
        "recall_micro = recall_score(new_targets_np, new_outputs_bin, average='micro')\n",
        "f1_micro = f1_score(new_targets_np, new_outputs_bin, average='micro')\n",
        "\n",
        "print(f'Macro Precision: {precision_macro} Macro Recall: {recall_macro} Macro F1: {f1_macro}')\n",
        "print(f'Micro Precision: {precision_micro} Micro Recall: {recall_micro} Micro F1: {f1_micro}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y6RizjlXBSF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(new_targets_np, new_outputs_bin)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ntfNSEVPgl"
      },
      "source": [
        "# Test with New Input Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gBriK_pVex0"
      },
      "outputs": [],
      "source": [
        "def classify_text(model, text, tokenizer, max_len, threshold=0.5):\n",
        "    # Prepare the text\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        text,\n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        padding='max_length',\n",
        "        return_token_type_ids=True,\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "    token_type_ids = inputs[\"token_type_ids\"].to(device)\n",
        "\n",
        "    # Get the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "    # Convert to probabilities\n",
        "    probabilities = torch.sigmoid(outputs).cpu().detach().numpy().tolist()\n",
        "\n",
        "    # Define the class labels in the same order that the model was trained on\n",
        "    class_labels =  ['Core Infrastructure & Protocols', 'Decentralized Finance (DeFi) & Financial Applications', 'Digital Assets & Collectibles (NFTs)', 'Decentralized Applications (DApps) & Gaming', 'DAO & Governance Mechanisms']\n",
        "\n",
        "\n",
        "    # Convert the probabilities to labels\n",
        "    predicted_labels = [class_labels[i] for i, prob in enumerate(probabilities[0]) if prob > threshold]\n",
        "\n",
        "    return probabilities, predicted_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYk97l5-VtVQ"
      },
      "outputs": [],
      "source": [
        "text = \"\"\n",
        "probabilities, predicted_labels = classify_text(model, text, tokenizer, MAX_LEN)\n",
        "print(\"Probabilities:\", probabilities)\n",
        "print(\"Predicted labels:\", predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I-nPOLgVtzk"
      },
      "outputs": [],
      "source": [
        "text = \"\"\n",
        "probabilities, predicted_labels = classify_text(model, text, tokenizer, MAX_LEN)\n",
        "print(\"Probabilities:\", probabilities)\n",
        "print(\"Predicted labels:\", predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfSzsTrirgkT"
      },
      "outputs": [],
      "source": [
        "text = \"\"\n",
        "probabilities, predicted_labels = classify_text(model, text, tokenizer, MAX_LEN)\n",
        "print(\"Probabilities:\", probabilities)\n",
        "print(\"Predicted labels:\", predicted_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
