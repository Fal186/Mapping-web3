{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qgeFEmGO16r",
        "outputId": "ed357a03-3330-43fd-d937-7cc8f4fe4150"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8KnOWZw6NI2"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRvKgWFiNX3e",
        "outputId": "99deec81-83cd-47a7-8d89-112e32cd3de0"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from transformers import AutoModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwrgGxyf6Vdx"
      },
      "source": [
        "# Setting seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_lFnQAn_19W"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04oLnrbGAyWv"
      },
      "outputs": [],
      "source": [
        "set_seed(43)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLw0U_AC6Yk7"
      },
      "source": [
        "# Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc5GbDOSnfWQ"
      },
      "outputs": [],
      "source": [
        "from requests import get as rget\n",
        "\n",
        "# Update URL to raw CSV file\n",
        "url = \"https://raw.githubusercontent.com/Fal186/Mapping-web3/refs/heads/main/dataset/web3_Stage2_emotional_tone.csv\"\n",
        "\n",
        "res = rget(url)\n",
        "with open('file.csv', 'wb+') as f:\n",
        "    f.write(res.content)\n",
        "\n",
        "data_df = pd.read_csv('file.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jJ2uW5CNjz8",
        "outputId": "e0fafffd-bba0-47b0-96b7-551003fc8e5d"
      },
      "outputs": [],
      "source": [
        "data_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxzUuRJHOKuE",
        "outputId": "cb7e8a0e-d14f-4076-95b5-4d9a55738d2b"
      },
      "outputs": [],
      "source": [
        "data_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO28y2VC6gof"
      },
      "source": [
        "# Selecting required columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JgnlISoOf_h"
      },
      "outputs": [],
      "source": [
        "train_df = data_df[['text', 'Optimism', 'Skepticism', 'Frustration', 'Curiosity',\n",
        "       'Concern']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hz6ZEJtOnlf"
      },
      "outputs": [],
      "source": [
        "target_list = [ 'Optimism', 'Skepticism', 'Frustration', 'Curiosity',\n",
        "       'Concern']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHUEw5zmhq3A"
      },
      "source": [
        "# Setting Base hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X99uZ4eYhGp3"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "PATIENCE = 2\n",
        "LEARNING_RATE = 2e-5\n",
        "GLOBAL_SEED = 43"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN0-q3TqzwH_"
      },
      "source": [
        "##Implementing Focal loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj17P0vozzJ4"
      },
      "outputs": [],
      "source": [
        "#FOCAL LOSS IMPLEMENTATION (M2)\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Focal Loss\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        # Alpha (Î±) balances positive/negative samples; Gamma (Î³) focuses on hard examples\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # 1. Calculate BCE Loss (Logits are used for numerical stability)\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "\n",
        "        # 2. Convert logits to probabilities (p)\n",
        "        p = torch.sigmoid(inputs)\n",
        "\n",
        "        # Calculate p_t (probability of the *true* class)\n",
        "        # If target is 1 (positive), p_t is p. If target is 0 (negative), p_t is 1-p.\n",
        "        p_t = p * targets + (1 - p) * (1 - targets)\n",
        "\n",
        "        # 3. Calculate Alpha Weighting (alpha_t)\n",
        "        # If target is 1 (positive), alpha_t is alpha. If target is 0 (negative), alpha_t is 1-alpha.\n",
        "        alpha_factor = targets * self.alpha + (1 - targets) * (1 - self.alpha)\n",
        "\n",
        "        # 4. Calculate Modulating Factor: ((1 - p_t) ^ gamma)\n",
        "        # This is the core term that suppresses loss for easy, well-classified examples.\n",
        "        modulating_factor = (1.0 - p_t) ** self.gamma\n",
        "\n",
        "        # 5. Combine and Calculate Final Loss\n",
        "        Focal_Loss = alpha_factor * modulating_factor * BCE_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return Focal_Loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return Focal_Loss.sum()\n",
        "        else:\n",
        "            return Focal_Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH7-eCoCQKrx"
      },
      "source": [
        "#Modular Model Switching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFtHe_rdPvkE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- MODEL MAPPING CONSTANTS ---\n",
        "MODEL_MAPPING = {\n",
        "    'BERT': 'bert-base-uncased',\n",
        "    'ROBERTA': 'roberta-base',\n",
        "    'CRYPTOBERT': 'ElKulako/cryptobert'\n",
        "}\n",
        "\n",
        "# --- UNIFIED MODEL CLASS ---\n",
        "class FlexibleTransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Unified class to load BERT, RoBERTa, or CryptoBERT and apply classifier head.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name_or_path, num_labels):\n",
        "        super(FlexibleTransformerModel, self).__init__()\n",
        "\n",
        "        self.base_model = AutoModel.from_pretrained(model_name_or_path, return_dict=True)\n",
        "        hidden_size = self.base_model.config.hidden_size\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.linear = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids=None):\n",
        "\n",
        "        output = self.base_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids # Handles models that don't use token_type_ids\n",
        "        )\n",
        "\n",
        "        # Use the hidden state of the [CLS] token (first token)\n",
        "        cls_output = output.last_hidden_state[:, 0, :]\n",
        "\n",
        "        output_dropout = self.dropout(cls_output)\n",
        "        output = self.linear(output_dropout)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq2sSjW4RSSo"
      },
      "outputs": [],
      "source": [
        "# --- STEP 1: Define YOUR MODEL ---\n",
        "\n",
        "# Define the number of output labels for your current classification task\n",
        "# Exapmle for Multli Label\n",
        "NUM_LABELS_STAGE = 5\n",
        "\n",
        "# Example for Multi-Class\n",
        "#NUM_LABELS_STAGE = 3\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFhZBCbNRXkI"
      },
      "outputs": [],
      "source": [
        "#Select the model\n",
        "CURRENT_MODEL_KEY = 'ROBERTA'  # <--- Change this string to 'BERT' or 'ROBERTA'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hW73qJhhUQw"
      },
      "source": [
        "# Preparing the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g3eG-kvOwf6"
      },
      "outputs": [],
      "source": [
        "#Set Max Lenght, max 512\n",
        "MAX_LEN = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8E6m1usO7Xa"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Load the Tokenizer based on the model\n",
        "def load_model_and_tokenizer(model_key, num_labels=5, device='cuda'):\n",
        "    \"\"\" Loads the model and tokenizer based on the simple model key. \"\"\"\n",
        "    model_path = MODEL_MAPPING.get(model_key)\n",
        "    if not model_path:\n",
        "        raise ValueError(f\"Unknown model key: {model_key}. Use one of {list(MODEL_MAPPING.keys())}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = FlexibleTransformerModel(model_path, num_labels)\n",
        "    model.to(device)\n",
        "\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "eb97455554b3477b94e0a7d2251c1141",
            "c33052b4f8464acbb0882d9bc7db6a83",
            "f7e5fc893b1645518c4a9f0534ff4eee",
            "12e587e3a2ab4737815729cf94c62f0d",
            "4cf8ece635124f8a9c57acf54135c2c2",
            "447cc2829fa44c789ea343ce518542ac",
            "866e786c060c4f3aa2188a9676833fe2",
            "f5c8bfa1ee2843f990ae128c7be68469",
            "370ab8ca2c3a4e6eaa77544ecc806183",
            "223b6f6b95ae47dcae649fefb5b5cdfd",
            "483fc75269534b0d9ec8636c053622cb"
          ]
        },
        "id": "VqCdBXFlRz0q",
        "outputId": "72c0e1a4-0350-40e4-c1a9-3cc36eb45b8d"
      },
      "outputs": [],
      "source": [
        "# Call the helper function to load the model and its matching tokenizer\n",
        "model, tokenizer = load_model_and_tokenizer(\n",
        "    model_key=CURRENT_MODEL_KEY,\n",
        "    num_labels=NUM_LABELS_STAGE,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(f\"Successfully loaded {CURRENT_MODEL_KEY} and its tokenizer.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrT5SmDGO_gj"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.title = df['text']\n",
        "        self.targets = self.df[target_list].values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index])\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1lpLevsPJJt"
      },
      "source": [
        "# Splitting & Tokenizing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpHexjOUVJt0",
        "outputId": "87f833af-012a-4960-9a0d-bf1b3320c7bf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "import torch\n",
        "from typing import Tuple\n",
        "\n",
        "#1. SEPARATE THE FINAL 10% TEST SET\n",
        "\n",
        "ALL_DATA_DF = train_df\n",
        "\n",
        "# Split the data into 90% Working Set (for k-fold) and 10% Final Test Set (held-out)\n",
        "# stratify=None is used here. If your target is multi-label, you might need a specialized splitter.\n",
        "FULL_TRAIN_VAL_DF, TEST_DF = train_test_split(\n",
        "    ALL_DATA_DF,\n",
        "    test_size=0.10,\n",
        "    random_state=GLOBAL_SEED\n",
        ")\n",
        "\n",
        "# Reset indices for clean subsetting later\n",
        "FULL_TRAIN_VAL_DF = FULL_TRAIN_VAL_DF.reset_index(drop=True)\n",
        "TEST_DF = TEST_DF.reset_index(drop=True)\n",
        "\n",
        "print(f\"Total Data: {len(ALL_DATA_DF)}\")\n",
        "print(f\"90% Working Set for K-Fold: {len(FULL_TRAIN_VAL_DF)} samples.\")\n",
        "print(f\"10% Final Test Set (Held Out): {len(TEST_DF)} samples.\")\n",
        "\n",
        "\n",
        "# --- 2. DEFINE THE DATASET CREATION FUNCTION ---\n",
        "\n",
        "def create_datasets_and_loaders(\n",
        "    working_df: pd.DataFrame,\n",
        "    test_df: pd.DataFrame,\n",
        "    tokenizer,\n",
        "    max_len: int,\n",
        "    batch_size: int,\n",
        "    subset_for_tuning: bool = True,\n",
        "    seed: int = 43 # Added seed parameter with a default value\n",
        ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "\n",
        "    # Create Custom Datasets from DataFrames\n",
        "    full_train_val_dataset = CustomDataset(working_df, tokenizer, max_len)\n",
        "    test_dataset = CustomDataset(test_df, tokenizer, max_len)\n",
        "\n",
        "    # --- 50% SUBSET LOGIC ---\n",
        "    if subset_for_tuning:\n",
        "        total_size = len(full_train_val_dataset)\n",
        "        subset_size = total_size // 2\n",
        "        remainder_size = total_size - subset_size\n",
        "\n",
        "        # Ensure reproducible split for the subset\n",
        "        generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "        # Select the 50% subset for quick tuning\n",
        "        train_val_working_set, _ = random_split(\n",
        "            full_train_val_dataset,\n",
        "            [subset_size, remainder_size],\n",
        "            generator=generator\n",
        "        )\n",
        "        print(f\"NOTE: Using 50% Subset for Hyperparameter Tuning: {len(train_val_working_set)} samples.\")\n",
        "    else:\n",
        "        # Use the full 90% working set for k-fold (or single full split)\n",
        "        train_val_working_set = full_train_val_dataset\n",
        "        print(f\"Using Full Working Set: {len(train_val_working_set)} samples.\")\n",
        "\n",
        "    #Split the Working Set into Train and Validation (80/20)\n",
        "\n",
        "    # We must split the working set into a train/validation split now for the quick search\n",
        "    # This split is NOT needed for the final K-Fold runs, but is necessary for the initial tuning.\n",
        "\n",
        "    generator = torch.Generator().manual_seed(seed + 1)\n",
        "\n",
        "    train_size = int(0.8 * len(train_val_working_set))\n",
        "    val_size = len(train_val_working_set) - train_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(\n",
        "        train_val_working_set,\n",
        "        [train_size, val_size],\n",
        "        generator=generator\n",
        "    )\n",
        "\n",
        "    print(f\"Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "    # --- Create DataLoaders ---\n",
        "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "    test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    return train_data_loader, val_data_loader, test_data_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4hGv088nyoP",
        "outputId": "0484d58e-cfaf-4b9c-bb96-cde4dd1f696e"
      },
      "outputs": [],
      "source": [
        "#DISTRIBUTION OF THE 90% WORKING SET (K-FOLD DATA)\n",
        "print(\"==================================================================\")\n",
        "print(\"             LABEL DISTRIBUTION CHECK (POST-SPLIT)                \")\n",
        "print(\"==================================================================\")\n",
        "\n",
        "# Counts for the 90% Working Set (will be used for K-Fold training)\n",
        "working_counts = FULL_TRAIN_VAL_DF[target_list].sum(axis=0)\n",
        "working_counts_percentage = (working_counts / len(FULL_TRAIN_VAL_DF)) * 100\n",
        "\n",
        "print(f\"### 90% Working Set ({len(FULL_TRAIN_VAL_DF)} Samples) ###\")\n",
        "print(\"Absolute Counts:\\n\", working_counts)\n",
        "print(\"\\nPercentage:\\n\", working_counts_percentage.round(2))\n",
        "\n",
        "#DISTRIBUTION OF THE 10% FINAL TEST SET (HELD-OUT DATA)\n",
        "\n",
        "# Counts for the 10% Final Test Set (will be used for final evaluation)\n",
        "test_counts = TEST_DF[target_list].sum(axis=0)\n",
        "test_counts_percentage = (test_counts / len(TEST_DF)) * 100\n",
        "\n",
        "print(f\"\\n### 10% Final Test Set ({len(TEST_DF)} Samples) ###\")\n",
        "print(\"Absolute Counts:\\n\", test_counts)\n",
        "print(\"\\nPercentage:\\n\", test_counts_percentage.round(2))\n",
        "print(\"------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKZbC_uaoSyg",
        "outputId": "f28aa8e0-416d-4b60-871d-d867ee5c32b2"
      },
      "outputs": [],
      "source": [
        "#OVERLAP CHECK (Working Set vs. Final Test Set)\n",
        "\n",
        "# We only need to check for overlap between the two main blocks\n",
        "working_texts = set(FULL_TRAIN_VAL_DF['text'])\n",
        "test_texts = set(TEST_DF['text'])\n",
        "\n",
        "# The intersection gives the number of samples present in both sets\n",
        "overlap = working_texts.intersection(test_texts)\n",
        "print(f\"\\nCRITICAL CHECK: Overlapping samples between Working Set and Final Test Set: {len(overlap)}\")\n",
        "\n",
        "if len(overlap) > 0:\n",
        "    print(\"WARNING: Overlap detected! This must be addressed before running K-Fold.\")\n",
        "else:\n",
        "    print(\"SUCCESS: No overlap detected between the Training/Validation and Test Sets.\")\n",
        "print(\"==================================================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eIYUWIEPP_a",
        "outputId": "dc6d1c4e-270a-44f2-de3a-50303a09e492"
      },
      "outputs": [],
      "source": [
        "print(\"--- Data Shapes Check (Post 90/10 Split) ---\")\n",
        "\n",
        "# 1. Check the 90% Working Set (The data for K-Fold)\n",
        "print(f\"FULL_TRAIN_VAL_DF Shape (90% Working Set): {FULL_TRAIN_VAL_DF.shape}\")\n",
        "\n",
        "# 2. Check the 10% Final Test Set (Held-Out Data)\n",
        "print(f\"TEST_DF Shape (10% Final Test Set): {TEST_DF.shape}\")\n",
        "\n",
        "print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAXwGSyCZswf",
        "outputId": "d21438e5-fe74-42ce-d3fd-a0fd5de1fb4c"
      },
      "outputs": [],
      "source": [
        "# If you still want to check the head of the Test Set\n",
        "print(\"\\nFULL_TRAIN_VAL_DF Head (Final Working Data):\")\n",
        "print(FULL_TRAIN_VAL_DF.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSm09Ay6ZrmU",
        "outputId": "e81f1e18-3d97-40f0-95f8-41ba27adf464"
      },
      "outputs": [],
      "source": [
        "# If you still want to check the head of the Test Set\n",
        "print(\"\\nTEST_DF Head (Final Test Data):\")\n",
        "print(TEST_DF.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMfVZre2PVRS",
        "outputId": "435809cf-5703-401e-ac19-d5f5ecdab175"
      },
      "outputs": [],
      "source": [
        "# Create the CustomDataset for each set\n",
        "full_train_val_dataset = CustomDataset(FULL_TRAIN_VAL_DF, tokenizer, MAX_LEN)\n",
        "test_dataset = CustomDataset(TEST_DF, tokenizer, MAX_LEN)\n",
        "\n",
        "print(\"CustomDatasets created for the Working Set and the Final Test Set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhaZ2dN6PePv",
        "outputId": "3399a33d-7571-4784-fb40-632c070781b5"
      },
      "outputs": [],
      "source": [
        "len(full_train_val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzjEWgTiAmn"
      },
      "source": [
        "# Additional functions for loading and saving checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK-rRna-P9cd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into\n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # FIX: weights_only=False allows loading checkpoints containing numpy/metadata\n",
        "    checkpoint = torch.load(checkpoint_fpath, map_location=device, weights_only=False)\n",
        "\n",
        "    # Initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    # Initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "    # Safely get metadata using .get() to prevent crashes\n",
        "    valid_loss_min = checkpoint.get('valid_loss_min', np.inf)\n",
        "    epoch = checkpoint.get('epoch', 1)\n",
        "    macro_f1 = checkpoint.get('macro_f1', 0.0) # Used for skip logic\n",
        "\n",
        "    # Return model, optimizer, epoch value, min validation loss, and f1 score\n",
        "    return model, optimizer, epoch, valid_loss_min, macro_f1\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, checkpoint_path)\n",
        "\n",
        "    # if it is a best model, copy that checkpoint file to best path\n",
        "    if is_best:\n",
        "        shutil.copyfile(checkpoint_path, best_model_path)\n",
        "        print(f\"ðŸ¥‡ Best model saved to: {best_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoc8eLxMQEYL"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Faa0Pam47V9T"
      },
      "source": [
        "Setting Up the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD5bZyhYQFpA"
      },
      "outputs": [],
      "source": [
        "# Initialize the FocalLoss instance once (gamma=2, alpha=0.25 are good starting points)\n",
        "FOCAL_LOSS_CRITERION = FocalLoss(alpha=0.25, gamma=2.0)\n",
        "def focal_loss_fn(outputs, targets):\n",
        "    return FOCAL_LOSS_CRITERION(outputs, targets)\n",
        "\n",
        "def cross_entropy_loss_fn(outputs, targets):\n",
        "    # CrossEntropyLoss requires targets to be class indices (LongTensor)\n",
        "    return nn.CrossEntropyLoss()(outputs, targets.argmax(dim=1))\n",
        "    # .argmax(dim=1) converts one-hot targets to class indices\n",
        "\n",
        "# Define a flag to switch loss\n",
        "IS_MULTI_CLASS = False\n",
        "\n",
        "def get_current_loss_fn(is_multi_class):\n",
        "    if is_multi_class:\n",
        "        # For Multi-Class, use Cross-Entropy\n",
        "        return cross_entropy_loss_fn\n",
        "    else:\n",
        "        # For Multi-Label, use Focal Loss\n",
        "        return focal_loss_fn\n",
        "\n",
        "optimizer = torch.optim.AdamW(params = model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSqb4o657dN2"
      },
      "source": [
        "Training and Validation Loop with Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_48OeKUvQVq2"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# NOTE: Ensure loss_fn, device, and the save_ckp function are defined elsewhere\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    # Always save the full state to the general checkpoint path\n",
        "    torch.save(state, checkpoint_path)\n",
        "\n",
        "    # If it is the best model, save the FULL STATE to the best model path\n",
        "    if is_best:\n",
        "        torch.save(state, best_model_path)\n",
        "        print(f\"Best model saved to {best_model_path}\")\n",
        "\n",
        "def train_model(n_epochs, training_loader, validation_loader, model,\n",
        "                optimizer, checkpoint_path, best_model_path, patience,\n",
        "                IS_MULTI_CLASS): # <-- Corrected function signature\n",
        "\n",
        "    # Initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.inf\n",
        "    no_improve = 0\n",
        "\n",
        "    # 1. INITIALIZE LISTS to hold the best validation data from the BEST epoch\n",
        "    best_val_targets_data = []\n",
        "    best_val_outputs_data = []\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "\n",
        "        # --- TRAINING LOOP (Uses loss_fn which should be Focal Loss) ---\n",
        "        model.train()\n",
        "        print(f'############# Epoch {epoch}: Training Start Â  #############')\n",
        "\n",
        "        # --- FIX: The loop over batches MUST be indented here ---\n",
        "        for batch_idx, data in enumerate(training_loader):\n",
        "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
        "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "           #DYNAMIC LOSS FUNCTION CALL\n",
        "            current_loss_fn = get_current_loss_fn(IS_MULTI_CLASS)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = current_loss_fn(outputs, targets) # <-- Dynamically switches loss function\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
        "        # -----------------------------------------------------------------\n",
        "\n",
        "        print(f'############# Epoch {epoch}: Training End Â  Â  #############')\n",
        "\n",
        "        # --- VALIDATION LOOP (Collecting data for M1) ---\n",
        "        print(f'############# Epoch {epoch}: Validation Start Â  #############')\n",
        "        model.eval()\n",
        "\n",
        "        # Initialize collectors for the current epoch's data\n",
        "        current_epoch_val_outputs = []\n",
        "        current_epoch_val_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # --- FIX: The loop over validation batches MUST be indented here ---\n",
        "            for batch_idx, data in enumerate(validation_loader, 0):\n",
        "                ids = data['input_ids'].to(device, dtype=torch.long)\n",
        "                mask = data['attention_mask'].to(device, dtype=torch.long)\n",
        "                token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "                targets = data['targets'].to(device, dtype=torch.float)\n",
        "                outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "                # Use correct Validation Loss function ---\n",
        "                if IS_MULTI_CLASS:\n",
        "                    # Multi-Class: Targets must be LongTensor indices for CrossEntropyLoss\n",
        "                    loss = nn.CrossEntropyLoss()(outputs, targets.argmax(dim=1).long())\n",
        "                else:\n",
        "                    # Multi-Label: Use standard BCE loss for validation tracking\n",
        "                    loss = nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "                valid_loss += ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
        "\n",
        "                # Use correct Activation function (Sigmoid vs Softmax) ---\n",
        "                if IS_MULTI_CLASS:\n",
        "                    # Multi-Class: Use Softmax\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                else:\n",
        "                    # Multi-Label: Use Sigmoid (for Adaptive Thresholds)\n",
        "                    probabilities = torch.sigmoid(outputs)\n",
        "\n",
        "                current_epoch_val_outputs.extend(probabilities.cpu().detach().numpy().tolist())\n",
        "                current_epoch_val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "        # -------------------------------------------------\n",
        "\n",
        "        train_loss /= len(training_loader)\n",
        "        valid_loss /= len(validation_loader)\n",
        "        print(f'Epoch: {epoch} \\tAverage Training Loss: {train_loss:.6f} \\tAverage Validation Loss: {valid_loss:.6f}')\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': valid_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "        # Save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model ...')\n",
        "\n",
        "            # 3. SAVE THE DATA from the current best epoch\n",
        "            best_val_targets_data = current_epoch_val_targets\n",
        "            best_val_outputs_data = current_epoch_val_outputs\n",
        "\n",
        "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "            valid_loss_min = valid_loss\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            print(f\"No improvement in validation loss for {no_improve} epoch(s).\")\n",
        "\n",
        "        # Early stopping\n",
        "        if no_improve >= patience:\n",
        "            print(\"Early stopping due to no improvement in validation loss.\")\n",
        "            break\n",
        "\n",
        "    # 4. RETURN the model and the data from the best epoch\n",
        "    return model, np.array(best_val_targets_data), np.array(best_val_outputs_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjcXXENu7C2w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the base directories clearly\n",
        "CKPT_DIR = \"/content/gdrive/MyDrive/ckpt_path_RoBERTa\"\n",
        "BEST_MODEL_DIR = \"/content/gdrive/MyDrive/Best_Model_RoBERTa\"\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "os.makedirs(BEST_MODEL_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7dTDouN6CjT"
      },
      "source": [
        "#Implementing Adaptive Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu2qCwiM5-df"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "def calculate_adaptive_thresholds(y_true, y_pred_proba):\n",
        "    \"\"\"\n",
        "    Calculates the optimal threshold for each class by maximizing the F1-score\n",
        "    on the validation set.\n",
        "\n",
        "    Args:\n",
        "        y_true (np.array): True binary labels (e.g., targets from validation set).\n",
        "        y_pred_proba (np.array): Predicted probabilities (sigmoid output from model).\n",
        "\n",
        "    Returns:\n",
        "        np.array: A 1D array of optimal thresholds, one for each class.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the number of classes (columns)\n",
        "    num_classes = y_true.shape[1]\n",
        "    optimal_thresholds = []\n",
        "\n",
        "    # Iterate through each class (column) independently\n",
        "    for i in range(num_classes):\n",
        "        best_f1 = 0\n",
        "        best_thresh = 0.5 # Default starting point\n",
        "\n",
        "        # Test a range of thresholds from 0.01 to 0.99\n",
        "        thresholds = np.arange(0.01, 1.00, 0.01)\n",
        "\n",
        "        for thresh in thresholds:\n",
        "            # Convert probabilities for this class to binary predictions using the current threshold\n",
        "            y_pred_bin = (y_pred_proba[:, i] > thresh).astype(int)\n",
        "\n",
        "            # Calculate F1 score using micro-average for this single class\n",
        "            # Note: For single-class optimization, the 'micro' average is the most straightforward\n",
        "            current_f1 = f1_score(y_true[:, i], y_pred_bin, average='binary')\n",
        "\n",
        "            if current_f1 > best_f1:\n",
        "                best_f1 = current_f1\n",
        "                best_thresh = thresh\n",
        "\n",
        "        optimal_thresholds.append(best_thresh)\n",
        "        #Optional: print(f\"Class {i}: Best F1 = {best_f1:.4f}, Thresh = {best_thresh:.2f}\")\n",
        "\n",
        "    return np.array(optimal_thresholds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS8efr0AeRkq"
      },
      "outputs": [],
      "source": [
        "#FUNCTION TO EVALUATE THE FINAL TEST SET\n",
        "def evaluate_test_set(model, test_data_loader):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the final 10% held-out test set.\n",
        "    Returns the predictions and true targets as NumPy arrays.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    test_outputs = []\n",
        "    test_targets = []\n",
        "\n",
        "    # NOTE: VALID_BATCH_SIZE is used here, but we will define it from global BATCH_SIZE\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_data_loader:\n",
        "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
        "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            # Multi-Label: Use Sigmoid\n",
        "            probabilities = torch.sigmoid(outputs)\n",
        "\n",
        "            test_outputs.extend(probabilities.cpu().detach().numpy().tolist())\n",
        "            test_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "\n",
        "    return np.array(test_targets), np.array(test_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXx9N3L2ic4E"
      },
      "source": [
        "# Start Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpt2jMurQdgX",
        "outputId": "d84abd06-9272-4a1c-ebd1-921c5568b60c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "import json # Added back the json import\n",
        "\n",
        "# Define a path for our tuning registry\n",
        "TUNING_REGISTRY_PATH = os.path.join(BEST_MODEL_DIR, \"tuning_results.json\")\n",
        "\n",
        "# --- 1. HYPERPARAMETER TUNING FUNCTION (50% Subset) ---\n",
        "\n",
        "def run_quick_tuning_run(full_df, test_df, model_key, num_labels, is_multi_class,\n",
        "                         max_len, batch_size, learning_rate, epochs, patience, seed):\n",
        "\n",
        "    # Use the 50% Subset for quick search\n",
        "    train_loader_quick, val_loader_quick, _ = create_datasets_and_loaders(\n",
        "        full_df,\n",
        "        test_df,\n",
        "        tokenizer,\n",
        "        max_len,\n",
        "        batch_size,\n",
        "        subset_for_tuning=True, # CRITICAL: This activates the 50% rule\n",
        "        seed=GLOBAL_SEED # Pass the seed to create_datasets_and_loaders\n",
        "    )\n",
        "\n",
        "    # Re-initialize Model and Optimizer\n",
        "    model, _ = load_model_and_tokenizer(model_key, num_labels=num_labels, device=device)\n",
        "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Define unique paths for this tuning run\n",
        "    base_name = f\"TUNING_{model_key}_LR{learning_rate}\"\n",
        "    ckpt_path = os.path.join(CKPT_DIR, f\"ckpth_{base_name}.pth\")\n",
        "    best_model_path = os.path.join(BEST_MODEL_DIR, f\"best_model_{base_name}.pth\")\n",
        "\n",
        "    # Define param_key unconditionally here\n",
        "    param_key = f\"{model_key}_LR{learning_rate}_EP{epochs}\" # Moved definition here\n",
        "\n",
        "    # Check the Registry First (Instant Load)\n",
        "    if os.path.exists(TUNING_REGISTRY_PATH):\n",
        "        with open(TUNING_REGISTRY_PATH, 'r') as f:\n",
        "            registry = json.load(f)\n",
        "\n",
        "        if param_key in registry:\n",
        "            print(f\"[REGISTRY] Found saved F1 for {param_key}: {registry[param_key]:.4f}\")\n",
        "            return registry[param_key]\n",
        "\n",
        "    # LOAD MODEL CHECK (Refined logic to handle missing macro_f1 more robustly)\n",
        "    if os.path.exists(best_model_path):\n",
        "        print(f\"\\n[FOUND] Existing file for LR: {learning_rate}. Checking contents...\")\n",
        "        try:\n",
        "            checkpoint = torch.load(best_model_path, map_location=device)\n",
        "\n",
        "            # Initialize variables\n",
        "            state_dict = None\n",
        "            macro_f1 = None\n",
        "\n",
        "            if isinstance(checkpoint, dict):\n",
        "                state_dict = checkpoint.get('state_dict') or \\\n",
        "                             checkpoint.get('model_state_dict') or \\\n",
        "                             checkpoint.get('model')\n",
        "                macro_f1 = checkpoint.get('macro_f1')\n",
        "\n",
        "                if state_dict is None and any('.weight' in k for k in checkpoint.keys()):\n",
        "                    state_dict = checkpoint\n",
        "            else:\n",
        "                state_dict = checkpoint\n",
        "\n",
        "            # --- DECIDE: RETURN SCORE OR RE-VALIDATE ---\n",
        "            if macro_f1 is not None:\n",
        "                print(f\"Returning saved F1 Score: {macro_f1:.4f}\")\n",
        "                return macro_f1\n",
        "\n",
        "            elif state_dict is not None:\n",
        "                print(\"Model weights found, but score missing. Re-validating now...\")\n",
        "                model, _ = load_model_and_tokenizer(model_key, num_labels=num_labels, device=device)\n",
        "                model.load_state_dict(state_dict)\n",
        "                model.to(device)\n",
        "\n",
        "                # Get the targets/outputs from the model by running validation\n",
        "                _, val_loader_quick, _ = create_datasets_and_loaders(\n",
        "                    full_df, test_df, tokenizer, max_len, batch_size, subset_for_tuning=True, seed=seed\n",
        "                )\n",
        "                val_targets_np, val_outputs_np = evaluate_test_set(model, val_loader_quick)\n",
        "\n",
        "                # Calculate F1 and proceed to save it properly\n",
        "                if is_multi_class:\n",
        "                    val_predictions = np.argmax(val_outputs_np, axis=1)\n",
        "                    val_targets_indices = np.argmax(val_targets_np, axis=1)\n",
        "                    macro_f1 = f1_score(val_targets_indices, val_predictions, average='macro')\n",
        "                else:\n",
        "                    optimal_thresholds = calculate_adaptive_thresholds(val_targets_np, val_outputs_np)\n",
        "                    val_predictions_bin = (val_outputs_np > optimal_thresholds)\n",
        "                    macro_f1 = f1_score(val_targets_np, val_predictions_bin, average='macro')\n",
        "\n",
        "                # Update the checkpoint with the calculated macro_f1\n",
        "                checkpoint['macro_f1'] = macro_f1\n",
        "                torch.save(checkpoint, best_model_path)\n",
        "                print(f\"Re-validated and saved F1: {macro_f1:.4f}\")\n",
        "                return macro_f1\n",
        "            else:\n",
        "                print(\"[WARN] File exists but contains no recognizable weights. Forcing re-train.\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR loading or processing checkpoint for LR: {learning_rate}: {e}. Forcing re-train.\")\n",
        "\n",
        "\n",
        "    print(f\"\\n--- Starting Tuning Run for LR: {learning_rate} ---\")\n",
        "\n",
        "    # Train the model (passing the correct IS_MULTI_CLASS flag)\n",
        "    trained_model, val_targets_np, val_outputs_np = train_model(\n",
        "        epochs, train_loader_quick, val_loader_quick, model,\n",
        "        optimizer, ckpt_path, best_model_path, patience,\n",
        "        IS_MULTI_CLASS=is_multi_class\n",
        "    )\n",
        "\n",
        "    # Calculate Final Validation Metric\n",
        "    if is_multi_class:\n",
        "        # Multi-Class: Convert outputs/targets to class indices and calculate F1\n",
        "        val_predictions = np.argmax(val_outputs_np, axis=1)\n",
        "        val_targets_indices = np.argmax(val_targets_np, axis=1)\n",
        "        macro_f1 = f1_score(val_targets_indices, val_predictions, average='macro')\n",
        "    else:\n",
        "        # Multi-Label: Calculate Adaptive Thresholds and then F1\n",
        "        optimal_thresholds = calculate_adaptive_thresholds(val_targets_np, val_outputs_np)\n",
        "        val_predictions_bin = (val_outputs_np > optimal_thresholds)\n",
        "        macro_f1 = f1_score(val_targets_np, val_predictions_bin, average='macro')\n",
        "\n",
        "    # This ensures the 'return' at the top of the function has data to read next time\n",
        "    checkpoint = torch.load(best_model_path)\n",
        "    checkpoint['macro_f1'] = macro_f1\n",
        "    torch.save(checkpoint, best_model_path)\n",
        "\n",
        "    # Load existing, update, and save back\n",
        "    current_registry = {}\n",
        "    if os.path.exists(TUNING_REGISTRY_PATH):\n",
        "        with open(TUNING_REGISTRY_PATH, 'r') as f:\n",
        "            current_registry = json.load(f)\n",
        "\n",
        "    current_registry[param_key] = float(macro_f1)\n",
        "\n",
        "    with open(TUNING_REGISTRY_PATH, 'w') as f:\n",
        "        json.dump(current_registry, f)\n",
        "    # ---------------------------------------\n",
        "\n",
        "    print(f\"Tuning Result (Val Macro F1): {macro_f1:.4f}\")\n",
        "    return macro_f1\n",
        "\n",
        "\n",
        "#EXECUTION BLOCK: SEARCH FOR BEST LR\n",
        "\n",
        "# Define the Learning Rates to test\n",
        "LEARNING_RATE_CANDIDATES = [5e-5, 2e-5, 3e-5] # Test common ranges\n",
        "results = {}\n",
        "\n",
        "# Use the constants defined earlier in your notebook\n",
        "TUNE_EPOCHS = 3 # Use fewer epochs for faster tuning (or match your original EPOCHS)\n",
        "\n",
        "print(\"\\n=====================================================\")\n",
        "print(f\"STARTING HYPERPARAMETER TUNING on 50% SUBSET\")\n",
        "print(\"=====================================================\")\n",
        "\n",
        "for lr in LEARNING_RATE_CANDIDATES:\n",
        "    f1 = run_quick_tuning_run(\n",
        "        full_df=FULL_TRAIN_VAL_DF,\n",
        "        test_df=TEST_DF,\n",
        "        model_key=CURRENT_MODEL_KEY,\n",
        "        num_labels=NUM_LABELS_STAGE,\n",
        "        is_multi_class=IS_MULTI_CLASS,\n",
        "        max_len=MAX_LEN,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        learning_rate=lr,\n",
        "        epochs=TUNE_EPOCHS,\n",
        "        patience=PATIENCE,\n",
        "        seed=GLOBAL_SEED\n",
        "    )\n",
        "    results[lr] = f1\n",
        "\n",
        "\n",
        "# Find the best learning rate\n",
        "best_lr = max(results, key=results.get)\n",
        "best_f1 = results[best_lr]\n",
        "\n",
        "print(\"\\n================== TUNING SUMMARY ==================\")\n",
        "print(f\"Results: {results}\")\n",
        "print(f\"BEST LEARNING RATE: {best_lr} (Validation Macro F1: {best_f1:.4f})\")\n",
        "print(\"=====================================================\")\n",
        "\n",
        "# Store the best LR to use for the final K-Fold run\n",
        "BEST_LEARNING_RATE_FOUND = best_lr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtQ9FNYZHDQZ"
      },
      "source": [
        "#Saving the best learning rate (hyperparameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgisOdxsHBZz",
        "outputId": "9c6bfd9b-6d04-47a7-b82d-7b225669d1dd"
      },
      "outputs": [],
      "source": [
        "print(\"\\n================== TUNING SUMMARY ==================\")\n",
        "print(f\"BEST LEARNING RATE: {best_lr} (Validation Macro F1: {best_f1:.4f})\")\n",
        "print(\"=====================================================\")\n",
        "\n",
        "# --- EXPORT THE HYPERPARAMETER TO A FILE (NEW) ---\n",
        "HYPERPARAM_DIR = \"/content/gdrive/MyDrive/Hyperparams\"\n",
        "os.makedirs(HYPERPARAM_DIR, exist_ok=True)\n",
        "FILE_PATH = os.path.join(HYPERPARAM_DIR, \"best_lr_cryptobert_stage1.txt\")\n",
        "\n",
        "with open(FILE_PATH, 'w') as f:\n",
        "    f.write(str(best_lr))\n",
        "\n",
        "print(f\"\\nSUCCESS: Best Learning Rate exported to {FILE_PATH}\")\n",
        "# END OF NOTEBOOK 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8skU_eb6FcU"
      },
      "source": [
        "#Training & Validating Using K-Fold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csfJGZLAe_9L"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from typing import Tuple\n",
        "\n",
        "# NOTE: Ensure all prerequisites are defined globally or imported:\n",
        "# CustomDataset, load_model_and_tokenizer, train_model,\n",
        "# calculate_adaptive_thresholds, evaluate_test_set, target_list\n",
        "\n",
        "def run_kfold_experiment(full_df: pd.DataFrame,\n",
        "                         test_df: pd.DataFrame,\n",
        "                         model_key: str,\n",
        "                         num_labels: int,\n",
        "                         is_multi_class: bool,\n",
        "                         k_folds: int = 5,\n",
        "                         epochs: int = EPOCHS,\n",
        "                         patience: int = PATIENCE,\n",
        "                         learning_rate: float = None,\n",
        "                         batch_size: int = BATCH_SIZE,\n",
        "                         seed: int = GLOBAL_SEED\n",
        "                         ) -> Tuple[float, float]:\n",
        "\n",
        "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
        "    fold_metrics = []\n",
        "    all_reports = []\n",
        "\n",
        "    full_dataset = CustomDataset(full_df, tokenizer, MAX_LEN)\n",
        "    test_dataset_obj = CustomDataset(test_df, tokenizer, MAX_LEN)\n",
        "    test_data_loader = DataLoader(test_dataset_obj, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(f\"--- Starting {k_folds}-Fold CV for {model_key} (LR: {learning_rate}) ---\")\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(kf.split(full_df)):\n",
        "        base_name = f\"{model_key}_FOLD{fold+1}_LR{learning_rate}\"\n",
        "        best_model_path = os.path.join(BEST_MODEL_DIR, f\"best_model_{base_name}.pth\")\n",
        "\n",
        "        # --- UPDATED RESUME LOGIC ---\n",
        "        if os.path.exists(best_model_path):\n",
        "            print(f\"â© Fold {fold+1} already exists. Running Fast Evaluation to load metrics...\")\n",
        "            try:\n",
        "                # FIX 1: Bypass PyTorch 2.6 security check\n",
        "                checkpoint = torch.load(best_model_path, map_location=device, weights_only=False)\n",
        "\n",
        "                # FIX 2: Re-load model and run test-set evaluation to populate all_reports\n",
        "                model_loaded, _ = load_model_and_tokenizer(model_key, num_labels=num_labels, device=device)\n",
        "                model_loaded.load_state_dict(checkpoint['state_dict'])\n",
        "                model_loaded.eval()\n",
        "\n",
        "                # Get validation targets for this fold to re-calculate thresholds (M1)\n",
        "                val_targets_np = full_df.iloc[val_index][target_list].values\n",
        "                val_subset = Subset(full_dataset, val_index)\n",
        "                val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "                # Re-generate outputs for Threshold Optimization\n",
        "                _, val_outputs_np = evaluate_test_set(model_loaded, val_loader)\n",
        "                optimal_thresholds = calculate_adaptive_thresholds(val_targets_np, val_outputs_np)\n",
        "\n",
        "                # Final evaluation on the 10% held-out test set\n",
        "                test_targets_np, test_outputs_np = evaluate_test_set(model_loaded, test_data_loader)\n",
        "                test_predictions_bin = (test_outputs_np > optimal_thresholds)\n",
        "\n",
        "                report_dict = classification_report(test_targets_np, test_predictions_bin,\n",
        "                                                    target_names=target_list, output_dict=True, zero_division=0)\n",
        "\n",
        "                all_reports.append(report_dict)\n",
        "                fold_metrics.append(report_dict['macro avg']['f1-score'])\n",
        "                print(f\"âœ… Fold {fold+1} metrics loaded successfully. Macro F1: {report_dict['macro avg']['f1-score']:.4f}\")\n",
        "                continue # Successfully skip training\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Failed to load metrics for Fold {fold+1}: {e}. Re-training...\")\n",
        "\n",
        "        # --- TRAINING SECTION (Only runs if fold doesn't exist or load failed) ---\n",
        "        print(f\"\\n====================== FOLD {fold+1}/{k_folds} ======================\")\n",
        "        train_subset = Subset(full_dataset, train_index)\n",
        "        val_subset = Subset(full_dataset, val_index)\n",
        "        train_data_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "        val_data_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        model, _ = load_model_and_tokenizer(model_key, num_labels=num_labels, device=device)\n",
        "        optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "        trained_model, val_targets_np, val_outputs_np = train_model(\n",
        "            epochs, train_data_loader, val_data_loader, model,\n",
        "            optimizer, os.path.join(CKPT_DIR, f\"ckpth_{base_name}.pth\"),\n",
        "            best_model_path, patience, IS_MULTI_CLASS=is_multi_class\n",
        "        )\n",
        "\n",
        "        # Standard Evaluation after training\n",
        "        test_targets_np, test_outputs_np = evaluate_test_set(trained_model, test_data_loader)\n",
        "        optimal_thresholds = calculate_adaptive_thresholds(val_targets_np, val_outputs_np)\n",
        "        test_predictions_bin = (test_outputs_np > optimal_thresholds)\n",
        "\n",
        "        report_dict = classification_report(test_targets_np, test_predictions_bin,\n",
        "                                            target_names=target_list, output_dict=True, zero_division=0)\n",
        "\n",
        "        all_reports.append(report_dict)\n",
        "        fold_metrics.append(report_dict['macro avg']['f1-score'])\n",
        "\n",
        "        # Save macro_f1 into checkpoint for easier future resumes\n",
        "        best_state = torch.load(best_model_path, map_location=device, weights_only=False)\n",
        "        best_state['macro_f1'] = report_dict['macro avg']['f1-score']\n",
        "        torch.save(best_state, best_model_path)\n",
        "\n",
        "    # 7. Final Aggregation and Reporting (After the Loop)\n",
        "    mean_f1 = np.mean(fold_metrics)\n",
        "    std_f1 = np.std(fold_metrics)\n",
        "    avg_report = {}\n",
        "\n",
        "    # Define which labels and averages to include\n",
        "    labels_to_average = target_list + ['macro avg', 'weighted avg']\n",
        "\n",
        "    for label in labels_to_average:\n",
        "        avg_report[label] = {}\n",
        "        # We now loop through all three core metrics\n",
        "        for metric in ['precision', 'recall', 'f1-score']:\n",
        "            # Collect the metric value for this label from all 5 reports\n",
        "            metric_values = [report[label][metric] for report in all_reports if label in report]\n",
        "            # Average the metric across the 5 folds\n",
        "            avg_report[label][metric] = np.mean(metric_values) if metric_values else 0.0\n",
        "\n",
        "    # 8. Print the Final Averaged Classification Report\n",
        "    print(\"\\n====================== AVERAGED PER-LABEL REPORT ======================\")\n",
        "    print(f\"Metrics are averaged across all {k_folds} K-Fold runs on the 10% Test Set:\")\n",
        "\n",
        "    for label in target_list:\n",
        "        print(f\"\\n--- {label} ---\")\n",
        "        print(f\"  Precision: {avg_report[label]['precision']:.4f}\")\n",
        "        print(f\"  Recall:    {avg_report[label]['recall']:.4f}\")\n",
        "        print(f\"  F1-Score:  {avg_report[label]['f1-score']:.4f}\")\n",
        "\n",
        "    # NEW: Expanded Macro Average Display\n",
        "    print(f\"\\nMACRO AVERAGE (Final Reported Metrics):\")\n",
        "    print(f\"  Precision: {avg_report['macro avg']['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {avg_report['macro avg']['recall']:.4f}\")\n",
        "    print(f\"  F1-Score:  {avg_report['macro avg']['f1-score']:.4f} Â± {std_f1:.4f}\")\n",
        "    print(\"=====================================================================\")\n",
        "\n",
        "    return avg_report['macro avg']['f1-score'], std_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsgqTDBcyGOU",
        "outputId": "5b9dce9d-f759-4243-9cf8-d47f7ec4713d"
      },
      "outputs": [],
      "source": [
        "# --- EXECUTION BLOCK ---\n",
        "print(\"Checking variables before calling...\")\n",
        "FULL_TRAIN_VAL_DF = FULL_TRAIN_VAL_DF.reset_index(drop=True)\n",
        "\n",
        "print(f\"Dataframe rows: {len(FULL_TRAIN_VAL_DF)}\")\n",
        "print(\"Attempting to call run_kfold_experiment now...\")\n",
        "\n",
        "final_f1, final_std = run_kfold_experiment(\n",
        "    full_df=FULL_TRAIN_VAL_DF,\n",
        "    test_df=TEST_DF,\n",
        "    model_key=CURRENT_MODEL_KEY,\n",
        "    num_labels=NUM_LABELS_STAGE,\n",
        "    is_multi_class=IS_MULTI_CLASS,\n",
        "    k_folds=5,\n",
        "    epochs=EPOCHS,\n",
        "    patience=PATIENCE,\n",
        "    learning_rate=BEST_LEARNING_RATE_FOUND,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=GLOBAL_SEED\n",
        ")\n",
        "\n",
        "print(\"K-Fold Experiment Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ntfNSEVPgl"
      },
      "source": [
        "# Test with New Input Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gBriK_pVex0"
      },
      "outputs": [],
      "source": [
        "def classify_text(model, text, tokenizer, max_len, mode='multi_label', threshold=0.5):\n",
        "    model.eval()\n",
        "    # Prepare the text\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        text,\n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        padding='max_length',\n",
        "        return_token_type_ids=True,\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "    token_type_ids = inputs[\"token_type_ids\"].to(device)\n",
        "\n",
        "    # Get the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
        "        # Check if output is a raw tensor or a HuggingFace object\n",
        "        logits = outputs if isinstance(outputs, torch.Tensor) else outputs.logits\n",
        "\n",
        "    # 1. Multi-Label Logic (Sigmoid + Adaptive Threshold) for Industry & Emotion\n",
        "    if mode == 'multi_label':\n",
        "        probabilities = torch.sigmoid(logits).cpu().detach().numpy().tolist()\n",
        "        \n",
        "        # Adaptive Threshold Calculation: Uses mean to capture layered intent\n",
        "        # Setting a floor of 0.3 ensures noise reduction\n",
        "        mean_prob = np.mean(probabilities[0])\n",
        "        adaptive_threshold = max(0.3, mean_prob)\n",
        "        \n",
        "        # Switch between stage 1 and stage 2\n",
        "        class_labels = [\n",
        "            'Core Infrastructure & Protocols', \n",
        "            'DAO & Governance Mechanisms', \n",
        "            'Decentralized Applications (DApps) & Gaming', \n",
        "            'Decentralized Finance (DeFi) & Financial Applications', \n",
        "            'Digital Assets & Collectibles (NFTs)'\n",
        "        ]\n",
        "        \n",
        "        predicted_labels = [class_labels[i] for i, prob in enumerate(probabilities[0]) if prob > adaptive_threshold]\n",
        "\n",
        "    # 2. Multi-Class Logic (Softmax) for Stage 3: Communicative Intent\n",
        "    else:\n",
        "        probabilities = torch.softmax(logits, dim=1).cpu().detach().numpy().tolist()\n",
        "        class_labels = ['Informational', 'Expressive', 'Promotional']\n",
        "        predicted_labels = [class_labels[np.argmax(probabilities[0])]]\n",
        "\n",
        "    return probabilities, predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYk97l5-VtVQ"
      },
      "outputs": [],
      "source": [
        "# Test your model with new Web3 discourse text\n",
        "text = \"The governance proposal for the new NFT staking pool on Uniswap is now live for community voting.\"\n",
        "\n",
        "# Use mode='multi_label' for Industry/Emotion stages\n",
        "# Use mode='multi_class' for Intent stage\n",
        "probabilities, predicted_labels = classify_text(model, text, tokenizer, MAX_LEN, mode='multi_label')\n",
        "\n",
        "print(\"Probabilities:\", probabilities)\n",
        "print(\"Predicted labels:\", predicted_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "c3ntfNSEVPgl"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12e587e3a2ab4737815729cf94c62f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_223b6f6b95ae47dcae649fefb5b5cdfd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_483fc75269534b0d9ec8636c053622cb",
            "value": "â€‡499M/499Mâ€‡[00:06&lt;00:00,â€‡63.9MB/s]"
          }
        },
        "223b6f6b95ae47dcae649fefb5b5cdfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370ab8ca2c3a4e6eaa77544ecc806183": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "447cc2829fa44c789ea343ce518542ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "483fc75269534b0d9ec8636c053622cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf8ece635124f8a9c57acf54135c2c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "866e786c060c4f3aa2188a9676833fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c33052b4f8464acbb0882d9bc7db6a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_447cc2829fa44c789ea343ce518542ac",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_866e786c060c4f3aa2188a9676833fe2",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "eb97455554b3477b94e0a7d2251c1141": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c33052b4f8464acbb0882d9bc7db6a83",
              "IPY_MODEL_f7e5fc893b1645518c4a9f0534ff4eee",
              "IPY_MODEL_12e587e3a2ab4737815729cf94c62f0d"
            ],
            "layout": "IPY_MODEL_4cf8ece635124f8a9c57acf54135c2c2"
          }
        },
        "f5c8bfa1ee2843f990ae128c7be68469": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7e5fc893b1645518c4a9f0534ff4eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5c8bfa1ee2843f990ae128c7be68469",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_370ab8ca2c3a4e6eaa77544ecc806183",
            "value": 498818054
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
