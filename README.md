# Mapping-web3: A Three-Stage Framework for Analyzing Web3 Discourse

This repository contains the dataset, model training scripts, and reproducibility materials for the paper titled:

**"What Drives Trust in Decentralized Communities? A Multidimensional Analysis of Web3 Discourse"**

---

## ğŸ“‚ Repository Structure

```
Mapping-web3/
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ web3_Stage1_industry_domain.csv
â”‚   â”œâ”€â”€ web3_Stage2_emotional_tone.csv
â”‚   â””â”€â”€ web3_Stage3_communicative_intent.csv
â”‚
â”œâ”€â”€ codes/
â”‚   â”œâ”€â”€ CryptoBERT/
â”‚   â”‚   â”œâ”€â”€ Stage 1/
â”‚   â”‚   â”œâ”€â”€ Stage 2/
â”‚   â”‚   â””â”€â”€ Stage 3/
â”‚   â””â”€â”€ RoBERTa/
â”‚       â”œâ”€â”€ Stage 1/
â”‚       â”œâ”€â”€ Stage 2/
â”‚       â””â”€â”€ Stage 3/
```

---

## ğŸ“˜ Project Overview

This project introduces a three-stage classification framework to analyze how Web3 is:

- **Discussed** (Stage 1: Industry Domain Classification)  
- **Felt** (Stage 2: Emotional Tone Classification)  
- **Communicated** (Stage 3: Communicative Intent Classification)  

Two transformer-based models (CryptoBERT and RoBERTa) were fine-tuned and evaluated across these tasks.

---

## ğŸ“ Dataset

Labeled datasets are available in the `/dataset` folder, with one CSV file per classification stage:

- `web3_Stage1_industry_domain.csv`  
- `web3_Stage2_emotional_tone.csv`  
- `web3_Stage3_communicative_intent.csv`  

Each file contains anonymized, preprocessed social media data from X (formerly Twitter), Reddit, Youtube, and additional data from ENS DAO Forum.

---

## ğŸ§  Model Training Scripts

The `/codes` folder contains all scripts for fine-tuning both CryptoBERT and RoBERTa across three stages.  
Each model has a dedicated subdirectory, organized by classification stage.

- Use the files in `codes/CryptoBERT` or `codes/RoBERTa` for training or evaluation  
- Fine-tuning configurations (batch size, learning rate, epochs) follow the best-performing setups from the paper  

---

## ğŸ” Reproducibility

- Data splits were stratified with a fixed random seed (43)  
- The models were trained using the Hugging Face Transformers library  
- For reproducibility, set environment seeds across Python, NumPy, and PyTorch as shown in the code  

---


## ğŸ”— Links

- ğŸ“„ [Paper (Coming Soon)](https://)  
- ğŸ“ [GitHub Repository](https://github.com/Fal186/Mapping-web3)
